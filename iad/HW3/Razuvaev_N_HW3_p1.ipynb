{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Введение в анализ данных\n",
    "## НИУ ВШЭ, 2019-2020 учебный год\n",
    "\n",
    "### Домашнее задание №3\n",
    "\n",
    "Задание выполнил(а): Разуваев Никита Сергеевич\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 09.04.2020\n",
    "\n",
    "Дедлайн: 24.04.2020 23:59 MSK\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом домашнем задании вы будете работать с линейной классификацией, попрактикуетесь на реальной задаче классификации текстов.\n",
    "\n",
    "Для решения этого домашнего задания намного удобнее будет использовать Colab, так как данных много.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "### Формат сдачи\n",
    "Загрузка файлов с решениями происходит в системе Anytask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztx03xvr9T95"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BVrrwTJNjuDt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_VMchexbjjTh",
    "outputId": "c1f66a1f-8851-42f3-e7e5-6c48d3c24707",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "# Датасет можно скачать здесь\n",
    "\n",
    "!wget https://www.dropbox.com/s/tg55q9mrziroyrs/train_subset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvXKae8q9nn-"
   },
   "source": [
    "### Данные\n",
    "\n",
    "Мы имеем дело с данными с торговой платформы Avito.\n",
    "Для каждого товара представлены следующие параметры:\n",
    " - title\n",
    " - description\n",
    " - Category_name\n",
    " - Category\n",
    "\n",
    "Имеется информация об объектах 50 классов.\n",
    "Задача: по новым объектам (title, description) предсказать Category.\n",
    "(Очевидно, что параметр Category_name для предсказания классов использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BqEuoDhqNgoa",
    "outputId": "b345f049-ae77-4d1b-a25f-4d4f447e63d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382220</th>\n",
       "      <td>Прихожая</td>\n",
       "      <td>В хорошем состоянии. Торг</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397529</th>\n",
       "      <td>Кордиант 215/55/16 Летние</td>\n",
       "      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584569</th>\n",
       "      <td>Стол</td>\n",
       "      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513100</th>\n",
       "      <td>Комбинезон</td>\n",
       "      <td>Размер-42/44</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091886</th>\n",
       "      <td>Ветровка</td>\n",
       "      <td>На 2 года</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "id                                   \n",
       "382220                    Прихожая   \n",
       "397529   Кордиант 215/55/16 Летние   \n",
       "584569                        Стол   \n",
       "2513100                 Комбинезон   \n",
       "1091886                   Ветровка   \n",
       "\n",
       "                                               description  \\\n",
       "id                                                           \n",
       "382220                           В хорошем состоянии. Торг   \n",
       "397529   Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...   \n",
       "584569   Стол, 2 рабочих места . Стол серого цвета, в д...   \n",
       "2513100                                       Размер-42/44   \n",
       "1091886                                          На 2 года   \n",
       "\n",
       "                     Category_name  Category  \n",
       "id                                            \n",
       "382220           Мебель и интерьер        20  \n",
       "397529       Запчасти и аксессуары        10  \n",
       "584569           Мебель и интерьер        20  \n",
       "2513100  Одежда, обувь, аксессуары        27  \n",
       "1091886     Детская одежда и обувь        29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_subset.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Kg8iPp7fiwGh",
    "outputId": "96ed00ed-b63b-4478-f2d4-66bda1110b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A1hvzAMETU2d"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMYU7zZw_cw-"
   },
   "source": [
    "Сразу разделим выборку на train и test.\n",
    "Никакие данные из test для обучения использовать нельзя!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6fia4_3vNprp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qDR8LtTJUIGt",
    "outputId": "fd4d5b55-a023-4129-9ff5-a6e8e24db915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Сапоги 46 размер новые', 'Сапоги 46 размер новые'],\n",
       "       ['Светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку. В эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iPhone 7 plus 128GB Red красный в наличии',\n",
       "        '\\xa0/\\n/\\n Данная цена только для подписчиков Instagram: iQmac/\\n/\\n Новый красный айфон 7 Plus в наличии это элегантный и мощный смартфон, который готов в полной мере раскрыть новые возможности iOS 10. Аппарат с 4-ядерным процессором А10 и 3 ГБ ОЗУ с легкостью решает самые ресурсоемкие задачи, позволяя наслаждаться быстродействием «тяжелых» приложений и игр на 5,5-дюймовом дисплее. Аппарат получил экран, как у iPad Pro, так что картинка теперь соответствует кинематографическому стандарту.'],\n",
       "       ['Пион Ирис Ромашка рассада',\n",
       "        'Пион куст 500 р ( более 10 шт)/\\nСаженец/ корень 100р/\\nРастут у нас более 70 лет/\\nРозовые, бордовые и белые/\\nНа фото цветы 2018г/\\nП. Зубчаниновка/\\nлибо пл. Революции/\\nЕсть ирисы, ромашка, клубника, боярышник и ирга'],\n",
       "       ['Кофта', 'Состояние отличное']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-ZEdlEGAXTD"
   },
   "source": [
    "### Токенизация (1 балл)\n",
    "\n",
    "\n",
    "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами.\n",
    "Можно использовать разные алгоритмы токенизации.\n",
    "Давайте пока остановимся на простом WordPunctTokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O9VgNlZ1Qy3o",
    "outputId": "59ef3a75-008e-47c5-fba8-a319eba13ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...\n",
      "after: здраствуйте . я , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "\n",
    "text = 'Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", preprocess(text),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_RYBKC26o1X"
   },
   "source": [
    "__Задание:__ Токенизируйте title и description в train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Z5WO-7tJUvbs"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "preprocess_func = np.vectorize(preprocess)\n",
    "X_train = preprocess_func(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['сапоги 46 размер новые', 'сапоги 46 размер новые'],\n",
       "       ['светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку . в эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iphone 7 plus 128gb red красный в наличии',\n",
       "        '/ / данная цена только для подписчиков instagram : iqmac / / новый красный айфон 7 plus в наличии это элегантный и мощный смартфон , который готов в полной мере раскрыть новые возможности ios 10 . аппарат с 4 - ядерным процессором а10 и 3 гб озу с легкостью решает самые ресурсоемкие задачи , позволяя наслаждаться быстродействием « тяжелых » приложений и игр на 5 , 5 - дюймовом дисплее . аппарат получил экран , как у ipad pro , так что картинка теперь соответствует кинематографическому стандарту .'],\n",
       "       ['пион ирис ромашка рассада',\n",
       "        'пион куст 500 р ( более 10 шт )/ саженец / корень 100р / растут у нас более 70 лет / розовые , бордовые и белые / на фото цветы 2018г / п . зубчаниновка / либо пл . революции / есть ирисы , ромашка , клубника , боярышник и ирга'],\n",
       "       ['кофта', 'состояние отличное'],\n",
       "       ['1 - к квартира , 33 м² , 4 / 5 эт .',\n",
       "        'продаётся уютная , тёплая квартира в экологически - чистом районе города , рядом сосновый бор , всегда чистый воздух . дом 2004 г ., хорошие соседи , на площадке 2 - е квартиры , развитая инфраструктура , в шаговой доступности поликлиника , школа , тк « орбита », вещевой рынок . квартира в хорошем состоянии . подходит под ипотеку , долгов , обременений , перепланировке нет . в квартире натяжные потолки , в ванной комнате стены выполнены из влагостойких стеновых панелей . возможен обмен на квартиру в г . магнитогорске , торг .'],\n",
       "       ['платье новое 60 размера',\n",
       "        'платье 60 размера , новое , красивого темно синего цвета , из трикотажной ткани : вискоза 95 %, эластина 5 % . а - образного силуэта с рукавом 2 / 3 . длинна по спинке 113см .'],\n",
       "       ['ваз 2114 samara , 2007',\n",
       "        'продам ваз 2114 2007 г . в . в хорошем состоянии . / 2 владельца , птс оригинал . / машина в родной краске , в дтп никогда не была ,/ днище целое не ржавое . по ходовой нареканий нет , сел и поехал . / имеется музыка , сигнализация 2 комплекта ключей , птф , передние стеклоподъемники ./ небольшой торг при осмотре . / обмен не интересует .'],\n",
       "       ['наушники блутус',\n",
       "        'долго держат заряд 4 - 5 часов , можно и больше при средней громкости выжать из них . вкладыши .'],\n",
       "       ['пальто tommy hilfiger',\n",
       "        'состояние нового . промахнулась с размером . пальто до - 10 - 12 градусов . / возможна пересылка по почте']],\n",
       "      dtype='<U3491')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VDnDSWwFDwFo"
   },
   "outputs": [],
   "source": [
    "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlIITUk0AsmS"
   },
   "source": [
    "### BOW (1.5 балла)\n",
    "\n",
    "Один из традиционных подходов -- построение bag of words.\n",
    "\n",
    "Метод состоит в следующем:\n",
    "\n",
    " - Составить словарь самых часто встречающихся слов\n",
    " - Для каждого примера посчитать, сколько раз каждое слово из словаря в нём встречается\n",
    "\n",
    "\n",
    "В sklearn есть CountVectorizer, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMKUttDWIF92"
   },
   "source": [
    "__Задание:__ Найдите 10000 самых частых слов из `title` и `description` обучающей выборки, отсортируйте их по убыванию частотности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZEVE_bzkRBx0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4a7503b0614935873ad0bed3ad3896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "all_words = np.concatenate([[j for j in i.split()] for i in tqdm(np.concatenate(X_train))])\n",
    "\n",
    "Voc, Cnt = np.unique(all_words, return_counts=True)\n",
    "bow_vocabulary = Voc[np.argsort(Cnt)][::-1][:10000]\n",
    "bow_vocabulary_cnt = Cnt[np.argsort(Cnt)][::-1][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '128',\n",
       " '2800',\n",
       " '71',\n",
       " 'c5',\n",
       " 'gigabyte',\n",
       " 'michelin',\n",
       " 'solaris',\n",
       " '»:/',\n",
       " 'атлант',\n",
       " 'болеро',\n",
       " 'верхней',\n",
       " 'воспользовавшись',\n",
       " 'г',\n",
       " 'грыж',\n",
       " 'джили',\n",
       " 'доступны',\n",
       " 'задач',\n",
       " 'зимних',\n",
       " 'использованию',\n",
       " 'кд',\n",
       " 'компания',\n",
       " 'красивые',\n",
       " 'левое',\n",
       " 'макс',\n",
       " 'мех',\n",
       " 'музей',\n",
       " 'натяжной',\n",
       " 'носили',\n",
       " 'однокомнатная',\n",
       " 'ответственный',\n",
       " 'пассажиров',\n",
       " 'плотная',\n",
       " 'покрытие',\n",
       " 'посуточно',\n",
       " 'приобретения',\n",
       " 'профессиональные',\n",
       " 'разрешение',\n",
       " 'решетку',\n",
       " 'сб',\n",
       " 'синее',\n",
       " 'создание',\n",
       " 'стандартные',\n",
       " 'счету',\n",
       " 'тонировка',\n",
       " 'удобна',\n",
       " 'фару',\n",
       " 'хюндай',\n",
       " 'шерстяной',\n",
       " 'этого']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка\n",
    "sorted(bow_vocabulary)[::200] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я не понимаю, как нужно отсортировать bow_vocabulary, чтобы в точности assert получить..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QTs70ZxVbk0J"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a1b23fdb8690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_vocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'12500'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'270'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'700'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'by'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'michael'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sonata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ø'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'аудиоподготовка'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'большим'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'веса'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'воспроизведения'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'габариты'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'гтд'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'джинсами'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'доступность'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'загрузки'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'зимней'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'использовался'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'квартала'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'коммуникации'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'кошки'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'лакированные'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'магазин'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'металл'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'мск'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'натуральным'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'носке'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'одному'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'отвечаем'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'пассат'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'плотно'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'покраску'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'постоянные'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'примеры'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'просьба'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'размещайте'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'репетитор'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'сантехник'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'сидения'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'современного'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'стала'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'схема'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'тон'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'удлиненная'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'фасад'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'цветами'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'шея'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'эту'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert sorted(bow_vocabulary)[::200] == ['!', '12500', '270', '700', 'by', 'gh', 'michael', 'sonata', 'ø', 'аудиоподготовка', 'большим', 'веса', 'воспроизведения', 'габариты', 'гтд', 'джинсами', 'доступность', 'загрузки', 'зимней', 'использовался', 'квартала', 'коммуникации', 'кошки', 'лакированные', 'магазин', 'металл', 'мск', 'натуральным', 'носке', 'одному', 'отвечаем', 'пассат', 'плотно', 'покраску', 'постоянные', 'примеры', 'просьба', 'размещайте', 'репетитор', 'сантехник', 'сидения', 'современного', 'стала', 'схема', 'тон', 'удлиненная', 'фасад', 'цветами', 'шея', 'эту']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4awkhecbR9om"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4,   12,  565,  866, 1598, 2533, 4117])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_bow(text: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из bow_vocabulary\n",
    "    указано количество его употреблений\n",
    "    \"\"\" \n",
    "    # Your code here\n",
    "    return np.sum([(bow_vocabulary == i).astype('int') for i in text.split()], axis=0)\n",
    "        \n",
    "\n",
    "# Проверка\n",
    "np.where(text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\") != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IZnJT2JbdXA3"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7b9aea9dbf6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m assert np.allclose(np.where(text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\") != 0)[0],\n\u001b[0;32m----> 2\u001b[0;31m                    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m   \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m565\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m866\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1601\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2539\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4063\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(np.where(text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\") != 0)[0],\n",
    "                   np.array([   1,    4,   12,  565,  866, 1601, 2539, 4063])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HR_D8Fn4pudv"
   },
   "outputs": [],
   "source": [
    "def items_to_bow(items: np.array, use_title=False) -> np.array:\n",
    "    \"\"\" Для каждого товара возвращает вектор его bow \"\"\"\n",
    "    # Давайте строить bow только из description товара\n",
    "    \n",
    "    # Your code here\n",
    "    if use_title:\n",
    "        return np.array([text_to_bow(i) for i in tqdm(items)])\n",
    "    else:\n",
    "        return np.array([text_to_bow(i[1]) for i in tqdm(items)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabb537fa92a46dfbaeb482d8be66b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2,    5,    6,    7,   12,   27,   41,   49,  110,\n",
       "         189,  207,  221, 2037, 3075, 7307, 9819]),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка\n",
    "np.where(items_to_bow([X_train[42]])[0] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pKdfMqbIetPA",
    "outputId": "9054ba46-57a4-4eea-cb3d-5d1764e1d56f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9a68d839ce4888a0b3f22a5aed236a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9630e6ef28e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m assert np.allclose(np.where(items_to_bow([X_train[42]])[0] != 0),\n\u001b[1;32m      2\u001b[0m                    np.array([   0, 1, 2, 5, 6, 7, 12, 27, 41, 49, 110,\n\u001b[0;32m----> 3\u001b[0;31m                                 189,  208,  221, 2032, 3052, 7179, 9568]),\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(np.where(items_to_bow([X_train[42]])[0] != 0),\n",
    "                   np.array([   0, 1, 2, 5, 6, 7, 12, 27, 41, 49, 110,\n",
    "                                189,  208,  221, 2032, 3052, 7179, 9568]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wwOZaEpMSQsZ",
    "outputId": "8a30c3af-3517-42bd-a5f3-36206b4b264a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69511b9d75b44a28007d5e17e68919a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d53957317074ae1abdf7f5cf5b91940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_bow = items_to_bow(X_train)\n",
    "X_test_bow = items_to_bow(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJoXiCWI7VF5"
   },
   "source": [
    "### Логистическая регрессия и SVC (1 балл)\n",
    "\n",
    "\n",
    "Теперь описание каждого товара представлено, как точка в многомерном пространстве.\n",
    "Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
    "\n",
    "Для BOW каждое измерение в пространстве -- какое-то слово.\n",
    "Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
    "\n",
    "Обучите логистическую регрессию и SVC с базовыми параметрами.\n",
    "\n",
    "**Подсказка: рассмотрите использование sparse-матриц - в них хранятся только ненулевые элементы.** `scipy.sparse.csr_matrix(X_train_bow)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse матрицы\n",
    "X_train_sparsed = sparse.csr_matrix(X_train_bow)\n",
    "X_test_sparsed = sparse.csr_matrix(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ky3HV1rTSS9L",
    "outputId": "612a5f0d-76bd-44f4-eeeb-63b517443797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5422222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-db7619240dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_lr_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0macc_lr_bow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Логистическая регрессия\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_sparsed, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_sparsed), y_test)\n",
    "print(acc_lr_bow)\n",
    "\n",
    "assert acc_lr_bow > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-c46ZT0lvF6T",
    "outputId": "4b1cb34a-201b-4dc2-9155-fdb6919c6c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d9e988befe0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_svc_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0macc_svc_bow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.68\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_sparsed, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_sparsed), y_test)\n",
    "print(acc_svc_bow)\n",
    "\n",
    "assert acc_svc_bow > 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy чуть выше 50% говорит об неудовлетворительном качестве предсказаний моделей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwKE57YZ1Hzn"
   },
   "source": [
    "### Модификация признаков (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewMlxQezL6Ax"
   },
   "source": [
    "Постройте признаковое пространство на конкатенации (через пробел) `title` и `description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "evqKo1r5L5BO"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Конкатенация\n",
    "X_train_concat = np.array([' '.join(i) for i in X_train])\n",
    "X_test_concat = np.array([' '.join(i) for i in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4c919298dd4d4e9491b50706fd3b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190cdf93b8324a558398cb20b69190a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BoW представление\n",
    "X_train_bow = items_to_bow(X_train_concat, use_title=True)\n",
    "X_test_bow = items_to_bow(X_test_concat, use_title=True)\n",
    "\n",
    "# sparse матрицы\n",
    "X_train_sparsed = sparse.csr_matrix(X_train_bow)\n",
    "X_test_sparsed = sparse.csr_matrix(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка\n",
    "X_train_bow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR = 0.5851111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Логистическая регрессия\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_sparsed, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_sparsed), y_test)\n",
    "print('accuracyLR =', acc_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracySVC = 0.5344444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_sparsed, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_sparsed), y_test)\n",
    "print('accuracySVC =', acc_svc_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление title слегка увеличило качество моделей. Но оно все еще неудовлетворительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvCAL3qGDByj"
   },
   "source": [
    "### mystem (1.5) балла\n",
    "\n",
    "Как можно заметить, в текстах одни и те же слова могут быть в разных падежах, а соответственно в bow это будут разные признаки. \n",
    "Чтобы исправить это, можно лемматизировать слова - с помощью библиотеки Mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "60oQ-6UgDcLF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mGvNHfVsDfhq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['здравствовать', ', ', 'ваш', ' ', 'благородие', '\\n']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "m.lemmatize(\"Здравствуйте, ваше благородие\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ \n",
    "* Лемматезируйте `title` и `description` с помощью mystem\n",
    "* Gостройте BoW-представление\n",
    "* Обучите на нём логистическую регрессию и SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b32fdc3b38e4d6387dde4495a7d5e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['сапог', ' ', '46', ' ', 'размер', ' ', 'новый', ' ', 'сапог', ' '],\n",
       "      dtype='<U250')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Лемматизация\n",
    "all_words = np.concatenate([m.lemmatize(X_train_concat[i]) for i in tqdm(range(len(X_train_concat)))])\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW-словарь\n",
    "Voc, Cnt = np.unique(all_words, return_counts=True)\n",
    "bow_vocabulary = Voc[np.argsort(Cnt)][::-1][:10000]\n",
    "bow_vocabulary_cnt = Cnt[np.argsort(Cnt)][::-1][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_lem(text: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из bow_vocabulary\n",
    "    указано количество его употреблений\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum([(bow_vocabulary == i).astype('int') for i in m.lemmatize(text)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_lem(items: np.array) -> np.array:\n",
    "    \"\"\" Для каждого товара возвращает вектор его bow \"\"\"\n",
    "    \n",
    "    return np.array([text_to_lem(i) for i in tqdm(items)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7dd27a482544529bfeb304a5984c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd7ca8441374084ae64a64c11549f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BoW представление\n",
    "X_train_bow = items_to_lem(X_train_concat)\n",
    "X_test_bow = items_to_lem(X_test_concat)\n",
    "\n",
    "# Sparse матрицы\n",
    "X_train_sparsed = sparse.csr_matrix(X_train_bow)\n",
    "X_test_sparsed = sparse.csr_matrix(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR = 0.5266666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Логистическая регрессия\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_sparsed, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_sparsed), y_test)\n",
    "print('accuracyLR =', acc_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracySVC = 0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_sparsed, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_sparsed), y_test)\n",
    "print('accuracySVC =', acc_svc_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что после лемматизации качество SVC значительно улучшилось. В то же время, качество линейной регрессии незначительно уменьшилось.\n",
    "\n",
    "66% для SVC -- уже удовлетворительный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXbsPtpfoB7m"
   },
   "source": [
    "### TF-IDF (1.5 балла)\n",
    "\n",
    "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
    "\n",
    "\n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "> \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "\n",
    "В sklearn есть TfidfVectorizer, но в этом задании его использовать нельзя.\n",
    "\n",
    "Давайте для простоты считать один tf-idf для title и description. Для каждого слова из bow_vocabulary нужно посчитать:\n",
    "1. Сколько раз оно встретилось в title и description во всём X_train\n",
    "2. В тексте скольких товаров встретилось это слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "_yIeoic7o3ES"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375b4528feb949f5b80e158de05f4d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[' ' '.' ' , ' ' / ' ' - ' 'в' 'и' '\\n']\n",
      "[0.         0.25053922 0.36192681 0.81246711 0.78484485 0.08198507\n",
      " 0.04111966 0.        ]\n"
     ]
    }
   ],
   "source": [
    "ndoc = len(X_train_concat)\n",
    "# tf-idf для каждого слова из bow_vocabulary\n",
    "idf_cnt = np.nan_to_num(\n",
    "    np.array([np.log(ndoc/np.sum([1 for j in X_train_concat if i in j])) for i in tqdm(bow_vocabulary)]),\n",
    "    nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Проверка\n",
    "print(bow_vocabulary[:8])\n",
    "print(idf_cnt[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6i5zFpD9rbtz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['новый' 'размер' '46' 'сапог']\n"
     ]
    }
   ],
   "source": [
    "def text_to_tfidf(text: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из bow_vocabulary указан tf-idf\n",
    "    \"\"\"\n",
    "\n",
    "    # Your code here\n",
    "    text_bow = np.sum([(bow_vocabulary == i).astype('int') for i in m.lemmatize(text)], axis=0)\n",
    "    return np.nan_to_num(text_bow / np.sum(text_bow), nan=0, posinf=0, neginf=0) * idf_cnt\n",
    "\n",
    "\n",
    "print(bow_vocabulary[np.where(text_to_tfidf(X_train_concat[0]) != 0)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_tfidf(items: np.array) -> np.array:\n",
    "    return np.array([text_to_tfidf(i) for i in tqdm(items)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YFA-8kE1RHk"
   },
   "source": [
    "### Модели на TF-IDF признаках (1 балл)\n",
    "\n",
    "Обучите логистическую регрессию и SVC, оцените качество (accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-ULrXsF1m5sU"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1c90fbb98f47499824770d7e3e200d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1eced1be1841e7be42eb99b5ba3bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# tf-idf представление\n",
    "X_train_bow = items_to_tfidf(X_train_concat)\n",
    "X_test_bow = items_to_tfidf(X_test_concat)\n",
    "\n",
    "# Sparse матрицы\n",
    "X_train_sparsed = sparse.csr_matrix(X_train_bow)\n",
    "X_test_sparsed = sparse.csr_matrix(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR = 0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Логистическая регрессия\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_sparsed, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_sparsed), y_test)\n",
    "print('accuracyLR =', acc_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracySVC = 0.7941111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_sparsed, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_sparsed), y_test)\n",
    "print('accuracySVC =', acc_svc_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря tf-idf взвешиванию удалось значительно увеличить качество моделей. \n",
    "\n",
    "Для логистической регрессии доля правильных ответов достигла 64%\n",
    "\n",
    "Для SVC -- 79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFdy3lUFDsOr"
   },
   "source": [
    "### Hashing Vectorizer (0.5 балла)\n",
    "\n",
    "Попробуйте использовать `sklearn.feature_extraction.text.HashingVectorizer` для векторизации текстов.\n",
    "Обязательно оцените качество работы алгоритмов классификации с использованием новой векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y666HTrqDq1m"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hash_vec = HashingVectorizer()\n",
    "X_train_sparsed = hash_vec.fit_transform(X_train_concat)\n",
    "X_test_sparsed = hash_vec.transform(X_test_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 1048576) (9000, 1048576)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sparsed.shape, X_test_sparsed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nikir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyLR = 0.7236666666666667\n"
     ]
    }
   ],
   "source": [
    "# Логистическая регрессия\n",
    "bow_model_lr = LogisticRegression(max_iter=100)\n",
    "bow_model_lr.fit(X_train_sparsed, y_train)\n",
    "acc_lr_bow = accuracy_score(bow_model_lr.predict(X_test_sparsed), y_test)\n",
    "print('accuracyLR =', acc_lr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracySVC = 0.8245555555555556\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "bow_model_svc = LinearSVC(max_iter=70)\n",
    "bow_model_svc.fit(X_train_sparsed, y_train)\n",
    "acc_svc_bow = accuracy_score(bow_model_svc.predict(X_test_sparsed), y_test)\n",
    "print('accuracySVC =', acc_svc_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизация с hashing еще сильнее улучшила качество моделей (да еще и очень быстро). Судя по всему, сказывается использование большого числа признаков -- 1048576\n",
    "\n",
    "Качество логистической регрессии достигло 72%, тогда как метод опорных векторов дает результат в 82% правильных ответов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQZ61xSsTpZI"
   },
   "source": [
    "### Word Vectors (1.5 балл)\n",
    "\n",
    "Давайте попробуем другой подход -- кажому слову сопоставим какой-то эмбеддинг (вектор).\n",
    "\n",
    "Вектора будут небольшой размерности. Таким образом мы снизим количество параметров в модели.\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах их интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## См. файл Razuvaev_N_HW3_p2.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVEdlFostSnX"
   },
   "source": [
    "### Что дальше?\n",
    "\n",
    "Решение каждого пункта 2 балла:\n",
    "\n",
    "\n",
    "\n",
    "1. N-Gram модели текстовой классификации\n",
    "    * Признаки - mystem\n",
    "    * n-gramm'ы - несколько слов подряд объединяются в один токен\n",
    "    * Модели - только логистическая регрессия\n",
    "    * Настоятельно рекомендуется использовать sparse-матрицы\n",
    "    \n",
    "\n",
    "2. Использовать Vowpal Wabbit вместо sklearn\n",
    "    * Признаки - обычный BoW title+description \n",
    "    * Главный вызов - заставить работать библиотеку и подготовить признаки\n",
    "\n",
    "3. Другие способы лемматизации (pymorphy2, spaCy)\n",
    "\n",
    "\n",
    "* Снабжайте код пояснениями;\n",
    "* Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
