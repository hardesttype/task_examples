{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa391c9",
   "metadata": {
    "id": "ffa391c9"
   },
   "source": [
    "# MHW 2\n",
    "\n",
    "> Выполнил: Разуваев Никита Сергеевич\n",
    "\n",
    "## Содержание:\n",
    "\n",
    "* [Задание 1](#task-1)\n",
    "    * Результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-top10-longest-sess.txt\n",
    "* [Задание 2.1](#task-2-1)\n",
    "    * Результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-top10-categories.txt\n",
    "* [Задание 2.2](#task-2-2)\n",
    "    * Результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-top10-words.txt\n",
    "* [Задание 2.3](#task-2-3)\n",
    "    * Результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-mean-price.txt\n",
    "* [Задание 2.4](#task-2-4)\n",
    "    * Результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-all-days-active-users.txt\n",
    "* [Задание 2.5](#task-2-5)\n",
    "    * Результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-uniq-users-per-day.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb319b",
   "metadata": {
    "id": "0afb319b"
   },
   "source": [
    "## Задание 1 <a class=\"anchor\" id=\"task-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209c5c3",
   "metadata": {
    "id": "7209c5c3"
   },
   "source": [
    "### Отправка данных в hdfs\n",
    "\n",
    "Воспользуемся датасетом скачанным в мини-дз 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1bee649",
   "metadata": {
    "id": "a1bee649",
    "outputId": "b45c4594-9f12-4881-d8d7-3d43a3ca5876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/storage/avito-context-ad-clicks\n",
      "VisitsStream.tsv\r\n"
     ]
    }
   ],
   "source": [
    "%cd \"~/storage/avito-context-ad-clicks\"\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb8cbf71",
   "metadata": {
    "id": "fb8cbf71",
    "outputId": "db0a3bde-dc52-4403-bb74-f0a753458192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID\tIPID\tAdID\tViewDate\r\n",
      "59703\t1259356\t469877\t2015-04-25 00:00:00.0\r\n",
      "154389\t1846749\t27252551\t2015-04-25 00:00:00.0\r\n",
      "218628\t2108380\t31685325\t2015-04-25 00:00:00.0\r\n",
      "231535\t837110\t18827716\t2015-04-25 00:00:00.0\r\n",
      "282306\t1654210\t29363673\t2015-04-25 00:00:00.0\r\n",
      "295068\t601505\t588324\t2015-04-25 00:00:00.0\r\n",
      "501897\t158476\t4103261\t2015-04-25 00:00:00.0\r\n",
      "655394\t631692\t9860544\t2015-04-25 00:00:00.0\r\n",
      "765603\t804403\t29475627\t2015-04-25 00:00:00.0\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 10 VisitsStream.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7c3e8",
   "metadata": {
    "id": "dab7c3e8"
   },
   "source": [
    "Обрежем названия столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442861ac",
   "metadata": {
    "id": "442861ac"
   },
   "outputs": [],
   "source": [
    "! sed -e '1'd VisitsStream.tsv > VisitsStreamNoHeader.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b0cc5b",
   "metadata": {
    "id": "f6b0cc5b",
    "outputId": "ee0daff9-4092-4c61-fe3b-19261154b1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisitsStreamNoHeader.tsv  VisitsStream.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1c4e8",
   "metadata": {
    "id": "56b1c4e8"
   },
   "source": [
    "Положим данные в hdsf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78e18e66",
   "metadata": {
    "id": "78e18e66",
    "outputId": "a444302d-58b0-4406-b862-00b5288faddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\r\n",
      "drwx------   - mapred hadoop          0 2022-01-26 00:09 /hadoop\r\n",
      "drwxr-xr-x   - hdfs   hadoop          0 2022-02-06 05:47 /system\r\n",
      "drwxrwxrwt   - hdfs   hadoop          0 2022-01-26 00:09 /tmp\r\n",
      "drwxrwxrwt   - hdfs   hadoop          0 2022-02-06 05:38 /user\r\n",
      "drwxrwxrwt   - hdfs   hadoop          0 2022-01-26 00:09 /var\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed216264",
   "metadata": {
    "id": "ed216264",
    "outputId": "c778c3e1-df6e-48d0-de15-44fc06c3ed87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/avito/data\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /user/avito/data\n",
    "! hdfs dfs -mkdir -p /user/avito/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f508589f",
   "metadata": {
    "id": "f508589f",
    "outputId": "dd85ec0d-a569-40a1-d91d-f61d036357aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.89 s, sys: 1.66 s, total: 9.55 s\n",
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! hdfs dfs -put VisitsStreamNoHeader.tsv /user/avito/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b745c4d",
   "metadata": {
    "id": "1b745c4d",
    "outputId": "5d01e0b8-8b93-4de3-f03a-0c666a3b1a98",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-06 22:23:21,935 INFO balancer.Balancer: namenodes  = [hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020]\n",
      "2022-02-06 22:23:21,955 INFO balancer.Balancer: parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]\n",
      "2022-02-06 22:23:21,955 INFO balancer.Balancer: included nodes = []\n",
      "2022-02-06 22:23:21,955 INFO balancer.Balancer: excluded nodes = []\n",
      "2022-02-06 22:23:21,955 INFO balancer.Balancer: source nodes = []\n",
      "Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved  NameNode\n",
      "2022-02-06 22:23:21,958 INFO balancer.NameNodeConnector: getBlocks calls for hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020 will be rate-limited to 20 per second\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Access denied for user root. Superuser privilege is required\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkSuperuserPrivilege(FSPermissionChecker.java:130)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkSuperuserPrivilege(FSNamesystem.java:4833)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockKeys(NameNodeRpcServer.java:669)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.getBlockKeys(NamenodeProtocolServerSideTranslatorPB.java:105)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:14720)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)\n",
      ".  Exiting ...\n",
      "Feb 6, 2022 10:23:22 PM  Balancing took 975.0 milliseconds\n"
     ]
    }
   ],
   "source": [
    "! sudo hdfs balancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27037e95",
   "metadata": {
    "id": "27037e95",
    "outputId": "d032bc8b-ae3f-4fe1-f0cd-9604d793ec40",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-06 22:23:27,506 INFO balancer.Balancer: namenodes  = [hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020]\n",
      "2022-02-06 22:23:27,509 INFO balancer.Balancer: parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]\n",
      "2022-02-06 22:23:27,509 INFO balancer.Balancer: included nodes = []\n",
      "2022-02-06 22:23:27,509 INFO balancer.Balancer: excluded nodes = []\n",
      "2022-02-06 22:23:27,509 INFO balancer.Balancer: source nodes = []\n",
      "Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved  NameNode\n",
      "2022-02-06 22:23:27,512 INFO balancer.NameNodeConnector: getBlocks calls for hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020 will be rate-limited to 20 per second\n",
      "2022-02-06 22:23:28,382 INFO balancer.Balancer: dfs.namenode.get-blocks.max-qps = 20 (default=20)\n",
      "2022-02-06 22:23:28,382 INFO balancer.Balancer: dfs.balancer.movedWinWidth = 5400000 (default=5400000)\n",
      "2022-02-06 22:23:28,383 INFO balancer.Balancer: dfs.balancer.moverThreads = 1000 (default=1000)\n",
      "2022-02-06 22:23:28,383 INFO balancer.Balancer: dfs.balancer.dispatcherThreads = 200 (default=200)\n",
      "2022-02-06 22:23:28,383 INFO balancer.Balancer: dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)\n",
      "2022-02-06 22:23:28,383 INFO balancer.Balancer: dfs.balancer.getBlocks.min-block-size = 10485760 (default=10485760)\n",
      "2022-02-06 22:23:28,383 INFO balancer.Balancer: dfs.datanode.balance.max.concurrent.moves = 50 (default=50)\n",
      "2022-02-06 22:23:28,383 INFO balancer.Balancer: dfs.datanode.balance.bandwidthPerSec = 10485760 (default=10485760)\n",
      "2022-02-06 22:23:28,389 INFO balancer.Balancer: dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)\n",
      "2022-02-06 22:23:28,389 INFO balancer.Balancer: dfs.blocksize = 268435456 (default=134217728)\n",
      "2022-02-06 22:23:28,407 INFO net.NetworkTopology: Adding a new node: /default-rack/10.128.0.24:9866\n",
      "2022-02-06 22:23:28,408 INFO balancer.Balancer: 0 over-utilized: []\n",
      "2022-02-06 22:23:28,408 INFO balancer.Balancer: 0 underutilized: []\n",
      "The cluster is balanced. Exiting...\n",
      "Feb 6, 2022 10:23:28 PM           0                  0 B                 0 B                0 B  hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020\n",
      "Feb 6, 2022 10:23:28 PM  Balancing took 1.031 seconds\n"
     ]
    }
   ],
   "source": [
    "! sudo chmod 0777 /usr/lib/hadoop/logs\n",
    "! sudo -u hdfs hdfs balancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d495f5dd",
   "metadata": {
    "id": "d495f5dd",
    "outputId": "4df9ddeb-667c-4973-a990-6459bb3e83b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop 13180996366 2022-02-06 22:21 /user/avito/data/VisitsStreamNoHeader.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/avito/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40dab28",
   "metadata": {
    "id": "e40dab28"
   },
   "source": [
    "### MapReduce\n",
    "\n",
    "Разобъем задачу на 2 MapReduce задачи: в первой - посчитаем длины сессий для всех пользователей, во второй - отсортируем все сессии по их длине в обратном порядке и выведем топ-10. Идея алгоритма следующая:\n",
    "\n",
    "1. Для первой MapReduce задачи делаем Маппер из изначальных данных в формат:\n",
    "\n",
    "    ```\n",
    "    UserID_1+ViewDate_11\n",
    "    UserID_1+ViewDate_12\n",
    "    UserID_2+ViewDate_21\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "2. Затем кастомный partitioner раскидывает данные по редьюсерам по ключу UserID (чтобы все строчки одного пользователя находились на 1-ой машине). Сортировка по обоим полям - сначала UserID, затем ViewDate.\n",
    "\n",
    "3. Редьюсер группирует данные по UserID. По каждому пользователю считается длина его максимальной сессии (пользуясь тем, что ViewDate также отсортирован по возрастанию). Данные выплевываются в формате:\n",
    "\n",
    "    ```\n",
    "    UserID_1    SessionLen_1\n",
    "    UserID_2    SessionLen_2\n",
    "    UserID_3    SessionLen_3\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "4. Во второй MapReduce задаче делаем маппинг с составным ключом:\n",
    "\n",
    "    ```\n",
    "    UserID_1+SessionLen_1\n",
    "    UserID_2+SessionLen_2\n",
    "    UserID_3+SessionLen_3\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "5. Сортируем по длине сессии ($SessionLen_{i}$) в обратном порядке, затем по $UserID_{i}$\n",
    "\n",
    "6. Редьюсер выводит первые 10 значений в формате:\n",
    "\n",
    "    ```\n",
    "    UserID_1    SessionLen_1\n",
    "    UserID_2    SessionLen_2\n",
    "    UserID_3    SessionLen_3\n",
    "    ...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c9c6cfd",
   "metadata": {
    "id": "6c9c6cfd"
   },
   "outputs": [],
   "source": [
    "! rm -r ~/storage/utils\n",
    "! mkdir ~/storage/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7302f04",
   "metadata": {
    "id": "b7302f04",
    "outputId": "f80d1713-9ce2-49b6-fd02-f51c30348aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/ubuntu/storage/utils/longest_sessions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '~/storage/utils/longest_sessions.py'\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import collections\n",
    "import datetime\n",
    "from itertools import islice, groupby\n",
    "\n",
    "def kv_stream(sep=\"\\t\"):\n",
    "    return map(lambda x: x.split(sep), sys.stdin)\n",
    "\n",
    "def csv_stream(sep=\"\\t\"):\n",
    "    return csv.reader(iter(sys.stdin.readline, ''), delimiter=sep)\n",
    "\n",
    "def rewind():\n",
    "    collections.deque(sys.stdin, maxlen=0)\n",
    "\n",
    "def mapper():\n",
    "    for row in csv_stream():\n",
    "        user_id, sess_start = row[0], row[3]\n",
    "        print(\"{}+{}\\t\".format(user_id.strip(), sess_start.strip()))\n",
    "\n",
    "def reducer():\n",
    "    for user_id, sess_starts in groupby(kv_stream('+'), lambda x: x[0]):\n",
    "        user_sess_starts = (x.strip() for _, x in sess_starts)\n",
    "\n",
    "        max_sess_length = 0\n",
    "        sess_length = 0\n",
    "        sess = datetime.datetime.strptime(\n",
    "            next(user_sess_starts), '%Y-%m-%d %H:%M:%S.%f'\n",
    "        )\n",
    "        for next_sess in user_sess_starts:\n",
    "            next_sess = datetime.datetime.strptime(\n",
    "                next_sess, '%Y-%m-%d %H:%M:%S.%f'\n",
    "            )\n",
    "            curr_sess_length = (next_sess - sess).total_seconds()\n",
    "\n",
    "            if curr_sess_length <= 900.0:\n",
    "                sess_length += curr_sess_length\n",
    "                if sess_length > max_sess_length:\n",
    "                    max_sess_length = sess_length\n",
    "            else:\n",
    "                sess_length = 0\n",
    "            \n",
    "            sess = next_sess\n",
    "        \n",
    "        print('{}\\t{}'.format(user_id, max_sess_length))\n",
    "    \n",
    "def top_10_mapper():\n",
    "    for k, v in kv_stream():\n",
    "        print(\"{}+{}\\t\".format(k.strip(), v.strip()))\n",
    "\n",
    "def top_10_reducer():\n",
    "    first_10_stream = islice(kv_stream('+'), 10)\n",
    "    \n",
    "    for user, sess_len in first_10_stream:\n",
    "        print(\"{}\\t{}\".format(user, sess_len.strip()))\n",
    "    rewind()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mr_command = sys.argv[1]\n",
    "    {\n",
    "        'map': mapper,\n",
    "        'reduce': reducer,\n",
    "        'top_10_map': top_10_mapper,\n",
    "        'top_10_reduce': top_10_reducer,\n",
    "    }[mr_command]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3f80e",
   "metadata": {},
   "source": [
    "Запускаем 1-ую MR задачу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3722112f",
   "metadata": {
    "id": "3722112f",
    "outputId": "921dd997-d68d-4d9d-f7d6-c23fbe840d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/avito/longest-sess': No such file or directory\n",
      "packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-3.2.2.jar] /tmp/streamjob1376684736749830578.jar tmpDir=null\n",
      "2022-02-06 22:24:59,556 INFO client.RMProxy: Connecting to ResourceManager at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:8032\n",
      "2022-02-06 22:24:59,748 INFO client.AHSProxy: Connecting to Application History server at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:10200\n",
      "2022-02-06 22:24:59,780 INFO client.RMProxy: Connecting to ResourceManager at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:8032\n",
      "2022-02-06 22:24:59,781 INFO client.AHSProxy: Connecting to Application History server at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:10200\n",
      "2022-02-06 22:25:00,041 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1644184388994_0001\n",
      "2022-02-06 22:25:00,383 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2022-02-06 22:25:01,321 INFO mapreduce.JobSubmitter: number of splits:50\n",
      "2022-02-06 22:25:01,990 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1644184388994_0001\n",
      "2022-02-06 22:25:01,992 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-02-06 22:25:02,290 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-02-06 22:25:02,291 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-02-06 22:25:02,930 INFO impl.YarnClientImpl: Submitted application application_1644184388994_0001\n",
      "2022-02-06 22:25:02,963 INFO mapreduce.Job: The url to track the job: http://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8088/proxy/application_1644184388994_0001/\n",
      "2022-02-06 22:25:02,964 INFO mapreduce.Job: Running job: job_1644184388994_0001\n",
      "2022-02-06 22:25:11,062 INFO mapreduce.Job: Job job_1644184388994_0001 running in uber mode : false\n",
      "2022-02-06 22:25:11,063 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-02-06 22:25:28,448 INFO mapreduce.Job:  map 1% reduce 0%\n",
      "2022-02-06 22:25:33,477 INFO mapreduce.Job:  map 2% reduce 0%\n",
      "2022-02-06 22:25:36,518 INFO mapreduce.Job:  map 3% reduce 0%\n",
      "2022-02-06 22:25:40,647 INFO mapreduce.Job:  map 4% reduce 0%\n",
      "2022-02-06 22:25:57,886 INFO mapreduce.Job:  map 5% reduce 0%\n",
      "2022-02-06 22:26:00,902 INFO mapreduce.Job:  map 6% reduce 0%\n",
      "2022-02-06 22:26:10,963 INFO mapreduce.Job:  map 7% reduce 0%\n",
      "2022-02-06 22:26:17,006 INFO mapreduce.Job:  map 8% reduce 0%\n",
      "2022-02-06 22:26:28,286 INFO mapreduce.Job:  map 9% reduce 0%\n",
      "2022-02-06 22:26:32,310 INFO mapreduce.Job:  map 10% reduce 0%\n",
      "2022-02-06 22:26:44,444 INFO mapreduce.Job:  map 11% reduce 0%\n",
      "2022-02-06 22:26:52,482 INFO mapreduce.Job:  map 12% reduce 0%\n",
      "2022-02-06 22:26:56,544 INFO mapreduce.Job:  map 13% reduce 0%\n",
      "2022-02-06 22:26:58,558 INFO mapreduce.Job:  map 14% reduce 0%\n",
      "2022-02-06 22:27:07,600 INFO mapreduce.Job:  map 15% reduce 0%\n",
      "2022-02-06 22:27:17,646 INFO mapreduce.Job:  map 16% reduce 0%\n",
      "2022-02-06 22:27:19,658 INFO mapreduce.Job:  map 17% reduce 0%\n",
      "2022-02-06 22:27:21,736 INFO mapreduce.Job:  map 18% reduce 0%\n",
      "2022-02-06 22:27:33,973 INFO mapreduce.Job:  map 19% reduce 0%\n",
      "2022-02-06 22:27:42,029 INFO mapreduce.Job:  map 20% reduce 0%\n",
      "2022-02-06 22:27:46,094 INFO mapreduce.Job:  map 21% reduce 0%\n",
      "2022-02-06 22:27:56,141 INFO mapreduce.Job:  map 22% reduce 0%\n",
      "2022-02-06 22:28:06,246 INFO mapreduce.Job:  map 23% reduce 0%\n",
      "2022-02-06 22:28:14,353 INFO mapreduce.Job:  map 24% reduce 0%\n",
      "2022-02-06 22:28:20,377 INFO mapreduce.Job:  map 25% reduce 0%\n",
      "2022-02-06 22:28:32,589 INFO mapreduce.Job:  map 26% reduce 0%\n",
      "2022-02-06 22:28:37,610 INFO mapreduce.Job:  map 27% reduce 0%\n",
      "2022-02-06 22:28:42,628 INFO mapreduce.Job:  map 28% reduce 0%\n",
      "2022-02-06 22:28:45,659 INFO mapreduce.Job:  map 29% reduce 0%\n",
      "2022-02-06 22:28:50,731 INFO mapreduce.Job:  map 30% reduce 0%\n",
      "2022-02-06 22:29:01,904 INFO mapreduce.Job:  map 31% reduce 0%\n",
      "2022-02-06 22:29:03,912 INFO mapreduce.Job:  map 32% reduce 0%\n",
      "2022-02-06 22:29:11,941 INFO mapreduce.Job:  map 33% reduce 0%\n",
      "2022-02-06 22:29:19,975 INFO mapreduce.Job:  map 34% reduce 0%\n",
      "2022-02-06 22:29:24,999 INFO mapreduce.Job:  map 35% reduce 0%\n",
      "2022-02-06 22:29:39,271 INFO mapreduce.Job:  map 36% reduce 0%\n",
      "2022-02-06 22:29:40,275 INFO mapreduce.Job:  map 37% reduce 0%\n",
      "2022-02-06 22:29:51,423 INFO mapreduce.Job:  map 38% reduce 0%\n",
      "2022-02-06 22:30:00,482 INFO mapreduce.Job:  map 39% reduce 0%\n",
      "2022-02-06 22:30:04,599 INFO mapreduce.Job:  map 40% reduce 0%\n",
      "2022-02-06 22:30:19,661 INFO mapreduce.Job:  map 41% reduce 0%\n",
      "2022-02-06 22:30:22,671 INFO mapreduce.Job:  map 42% reduce 0%\n",
      "2022-02-06 22:30:26,686 INFO mapreduce.Job:  map 43% reduce 0%\n",
      "2022-02-06 22:30:30,779 INFO mapreduce.Job:  map 44% reduce 0%\n",
      "2022-02-06 22:30:41,921 INFO mapreduce.Job:  map 45% reduce 0%\n",
      "2022-02-06 22:30:43,928 INFO mapreduce.Job:  map 45% reduce 5%\n",
      "2022-02-06 22:30:50,064 INFO mapreduce.Job:  map 46% reduce 5%\n",
      "2022-02-06 22:30:55,142 INFO mapreduce.Job:  map 47% reduce 5%\n",
      "2022-02-06 22:31:02,169 INFO mapreduce.Job:  map 48% reduce 5%\n",
      "2022-02-06 22:31:11,312 INFO mapreduce.Job:  map 49% reduce 5%\n",
      "2022-02-06 22:31:23,404 INFO mapreduce.Job:  map 50% reduce 5%\n",
      "2022-02-06 22:31:27,417 INFO mapreduce.Job:  map 51% reduce 5%\n",
      "2022-02-06 22:31:31,478 INFO mapreduce.Job:  map 52% reduce 5%\n",
      "2022-02-06 22:31:37,623 INFO mapreduce.Job:  map 52% reduce 6%\n",
      "2022-02-06 22:31:42,639 INFO mapreduce.Job:  map 53% reduce 6%\n",
      "2022-02-06 22:31:50,756 INFO mapreduce.Job:  map 54% reduce 6%\n",
      "2022-02-06 22:31:55,827 INFO mapreduce.Job:  map 55% reduce 6%\n",
      "2022-02-06 22:32:06,928 INFO mapreduce.Job:  map 56% reduce 6%\n",
      "2022-02-06 22:32:13,961 INFO mapreduce.Job:  map 57% reduce 6%\n",
      "2022-02-06 22:32:25,042 INFO mapreduce.Job:  map 58% reduce 6%\n",
      "2022-02-06 22:32:31,168 INFO mapreduce.Job:  map 59% reduce 6%\n",
      "2022-02-06 22:32:36,321 INFO mapreduce.Job:  map 60% reduce 6%\n",
      "2022-02-06 22:32:43,422 INFO mapreduce.Job:  map 61% reduce 6%\n",
      "2022-02-06 22:32:44,426 INFO mapreduce.Job:  map 61% reduce 7%\n",
      "2022-02-06 22:32:52,455 INFO mapreduce.Job:  map 62% reduce 7%\n",
      "2022-02-06 22:32:56,487 INFO mapreduce.Job:  map 63% reduce 7%\n",
      "2022-02-06 22:33:07,526 INFO mapreduce.Job:  map 64% reduce 7%\n",
      "2022-02-06 22:33:16,618 INFO mapreduce.Job:  map 65% reduce 7%\n",
      "2022-02-06 22:33:25,646 INFO mapreduce.Job:  map 66% reduce 7%\n",
      "2022-02-06 22:33:32,667 INFO mapreduce.Job:  map 67% reduce 7%\n",
      "2022-02-06 22:33:37,760 INFO mapreduce.Job:  map 68% reduce 7%\n",
      "2022-02-06 22:33:43,874 INFO mapreduce.Job:  map 68% reduce 8%\n",
      "2022-02-06 22:33:46,883 INFO mapreduce.Job:  map 69% reduce 8%\n",
      "2022-02-06 22:33:54,919 INFO mapreduce.Job:  map 70% reduce 8%\n",
      "2022-02-06 22:33:58,946 INFO mapreduce.Job:  map 71% reduce 8%\n",
      "2022-02-06 22:34:13,035 INFO mapreduce.Job:  map 72% reduce 8%\n",
      "2022-02-06 22:34:19,057 INFO mapreduce.Job:  map 73% reduce 8%\n",
      "2022-02-06 22:34:31,094 INFO mapreduce.Job:  map 74% reduce 8%\n",
      "2022-02-06 22:34:34,106 INFO mapreduce.Job:  map 75% reduce 8%\n",
      "2022-02-06 22:34:50,297 INFO mapreduce.Job:  map 76% reduce 8%\n",
      "2022-02-06 22:34:55,325 INFO mapreduce.Job:  map 77% reduce 8%\n",
      "2022-02-06 22:35:00,431 INFO mapreduce.Job:  map 78% reduce 8%\n",
      "2022-02-06 22:35:13,534 INFO mapreduce.Job:  map 79% reduce 8%\n",
      "2022-02-06 22:35:16,543 INFO mapreduce.Job:  map 80% reduce 8%\n",
      "2022-02-06 22:35:31,594 INFO mapreduce.Job:  map 81% reduce 8%\n",
      "2022-02-06 22:35:35,606 INFO mapreduce.Job:  map 82% reduce 8%\n",
      "2022-02-06 22:35:50,826 INFO mapreduce.Job:  map 83% reduce 8%\n",
      "2022-02-06 22:35:52,832 INFO mapreduce.Job:  map 84% reduce 8%\n",
      "2022-02-06 22:36:02,949 INFO mapreduce.Job:  map 85% reduce 8%\n",
      "2022-02-06 22:36:08,967 INFO mapreduce.Job:  map 85% reduce 9%\n",
      "2022-02-06 22:36:13,997 INFO mapreduce.Job:  map 86% reduce 9%\n",
      "2022-02-06 22:36:21,072 INFO mapreduce.Job:  map 87% reduce 9%\n",
      "2022-02-06 22:36:33,108 INFO mapreduce.Job:  map 88% reduce 9%\n",
      "2022-02-06 22:36:38,121 INFO mapreduce.Job:  map 89% reduce 9%\n",
      "2022-02-06 22:36:42,180 INFO mapreduce.Job:  map 90% reduce 9%\n",
      "2022-02-06 22:36:45,204 INFO mapreduce.Job:  map 90% reduce 10%\n",
      "2022-02-06 22:36:54,290 INFO mapreduce.Job:  map 91% reduce 10%\n",
      "2022-02-06 22:36:57,299 INFO mapreduce.Job:  map 92% reduce 10%\n",
      "2022-02-06 22:37:06,401 INFO mapreduce.Job:  map 93% reduce 10%\n",
      "2022-02-06 22:37:15,431 INFO mapreduce.Job:  map 94% reduce 10%\n",
      "2022-02-06 22:37:18,512 INFO mapreduce.Job:  map 95% reduce 10%\n",
      "2022-02-06 22:37:28,544 INFO mapreduce.Job:  map 97% reduce 10%\n",
      "2022-02-06 22:37:35,606 INFO mapreduce.Job:  map 98% reduce 10%\n",
      "2022-02-06 22:37:39,622 INFO mapreduce.Job:  map 99% reduce 10%\n",
      "2022-02-06 22:37:45,644 INFO mapreduce.Job:  map 99% reduce 11%\n",
      "2022-02-06 22:37:54,730 INFO mapreduce.Job:  map 99% reduce 22%\n",
      "2022-02-06 22:38:08,768 INFO mapreduce.Job:  map 100% reduce 22%\n",
      "2022-02-06 22:38:20,800 INFO mapreduce.Job:  map 100% reduce 24%\n",
      "2022-02-06 22:38:26,816 INFO mapreduce.Job:  map 100% reduce 25%\n",
      "2022-02-06 22:38:28,822 INFO mapreduce.Job:  map 100% reduce 36%\n",
      "2022-02-06 22:38:32,833 INFO mapreduce.Job:  map 100% reduce 38%\n",
      "2022-02-06 22:38:38,850 INFO mapreduce.Job:  map 100% reduce 39%\n",
      "2022-02-06 22:38:44,870 INFO mapreduce.Job:  map 100% reduce 41%\n",
      "2022-02-06 22:38:50,887 INFO mapreduce.Job:  map 100% reduce 42%\n",
      "2022-02-06 22:38:56,903 INFO mapreduce.Job:  map 100% reduce 44%\n",
      "2022-02-06 22:39:08,934 INFO mapreduce.Job:  map 100% reduce 45%\n",
      "2022-02-06 22:39:32,997 INFO mapreduce.Job:  map 100% reduce 46%\n",
      "2022-02-06 22:39:37,010 INFO mapreduce.Job:  map 100% reduce 47%\n",
      "2022-02-06 22:39:43,027 INFO mapreduce.Job:  map 100% reduce 49%\n",
      "2022-02-06 22:39:49,044 INFO mapreduce.Job:  map 100% reduce 51%\n",
      "2022-02-06 22:39:55,065 INFO mapreduce.Job:  map 100% reduce 52%\n",
      "2022-02-06 22:40:01,081 INFO mapreduce.Job:  map 100% reduce 54%\n",
      "2022-02-06 22:40:07,098 INFO mapreduce.Job:  map 100% reduce 55%\n",
      "2022-02-06 22:40:09,104 INFO mapreduce.Job:  map 100% reduce 56%\n",
      "2022-02-06 22:40:13,115 INFO mapreduce.Job:  map 100% reduce 57%\n",
      "2022-02-06 22:40:17,126 INFO mapreduce.Job:  map 100% reduce 58%\n",
      "2022-02-06 22:40:23,142 INFO mapreduce.Job:  map 100% reduce 59%\n",
      "2022-02-06 22:40:25,149 INFO mapreduce.Job:  map 100% reduce 60%\n",
      "2022-02-06 22:40:29,160 INFO mapreduce.Job:  map 100% reduce 61%\n",
      "2022-02-06 22:40:35,175 INFO mapreduce.Job:  map 100% reduce 63%\n",
      "2022-02-06 22:40:41,194 INFO mapreduce.Job:  map 100% reduce 64%\n",
      "2022-02-06 22:40:43,199 INFO mapreduce.Job:  map 100% reduce 65%\n",
      "2022-02-06 22:40:47,209 INFO mapreduce.Job:  map 100% reduce 66%\n",
      "2022-02-06 22:40:53,224 INFO mapreduce.Job:  map 100% reduce 68%\n",
      "2022-02-06 22:40:59,240 INFO mapreduce.Job:  map 100% reduce 69%\n",
      "2022-02-06 22:41:15,280 INFO mapreduce.Job:  map 100% reduce 70%\n",
      "2022-02-06 22:41:39,346 INFO mapreduce.Job:  map 100% reduce 71%\n",
      "2022-02-06 22:42:05,419 INFO mapreduce.Job:  map 100% reduce 72%\n",
      "2022-02-06 22:42:29,481 INFO mapreduce.Job:  map 100% reduce 73%\n",
      "2022-02-06 22:42:55,548 INFO mapreduce.Job:  map 100% reduce 74%\n",
      "2022-02-06 22:43:19,615 INFO mapreduce.Job:  map 100% reduce 75%\n",
      "2022-02-06 22:43:43,679 INFO mapreduce.Job:  map 100% reduce 76%\n",
      "2022-02-06 22:44:09,747 INFO mapreduce.Job:  map 100% reduce 77%\n",
      "2022-02-06 22:44:33,816 INFO mapreduce.Job:  map 100% reduce 78%\n",
      "2022-02-06 22:44:57,880 INFO mapreduce.Job:  map 100% reduce 79%\n",
      "2022-02-06 22:45:22,951 INFO mapreduce.Job:  map 100% reduce 80%\n",
      "2022-02-06 22:45:47,022 INFO mapreduce.Job:  map 100% reduce 81%\n",
      "2022-02-06 22:46:14,102 INFO mapreduce.Job:  map 100% reduce 82%\n",
      "2022-02-06 22:46:38,169 INFO mapreduce.Job:  map 100% reduce 83%\n",
      "2022-02-06 22:47:02,233 INFO mapreduce.Job:  map 100% reduce 84%\n",
      "2022-02-06 22:47:28,309 INFO mapreduce.Job:  map 100% reduce 85%\n",
      "2022-02-06 22:47:52,379 INFO mapreduce.Job:  map 100% reduce 86%\n",
      "2022-02-06 22:48:16,440 INFO mapreduce.Job:  map 100% reduce 87%\n",
      "2022-02-06 22:48:41,506 INFO mapreduce.Job:  map 100% reduce 88%\n",
      "2022-02-06 22:49:05,567 INFO mapreduce.Job:  map 100% reduce 89%\n",
      "2022-02-06 22:49:29,633 INFO mapreduce.Job:  map 100% reduce 90%\n",
      "2022-02-06 22:49:55,704 INFO mapreduce.Job:  map 100% reduce 91%\n",
      "2022-02-06 22:50:19,769 INFO mapreduce.Job:  map 100% reduce 92%\n",
      "2022-02-06 22:50:43,838 INFO mapreduce.Job:  map 100% reduce 93%\n",
      "2022-02-06 22:51:10,923 INFO mapreduce.Job:  map 100% reduce 94%\n",
      "2022-02-06 22:51:34,990 INFO mapreduce.Job:  map 100% reduce 95%\n",
      "2022-02-06 22:52:00,056 INFO mapreduce.Job:  map 100% reduce 96%\n",
      "2022-02-06 22:52:24,118 INFO mapreduce.Job:  map 100% reduce 97%\n",
      "2022-02-06 22:52:50,184 INFO mapreduce.Job:  map 100% reduce 98%\n",
      "2022-02-06 22:53:20,264 INFO mapreduce.Job:  map 100% reduce 99%\n",
      "2022-02-06 22:54:24,428 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-02-06 22:54:57,513 INFO mapreduce.Job: Job job_1644184388994_0001 completed successfully\n",
      "2022-02-06 22:54:57,598 INFO mapreduce.Job: Counters: 56\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2413039976\n",
      "\t\tFILE: Number of bytes written=3586637320\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=13187426494\n",
      "\t\tHDFS: Number of bytes written=46224720\n",
      "\t\tHDFS: Number of read operations=165\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=9\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=50\n",
      "\t\tLaunched reduce tasks=3\n",
      "\t\tData-local map tasks=24\n",
      "\t\tRack-local map tasks=26\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=10593489\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=19813056\n",
      "\t\tTotal time spent by all map tasks (ms)=3531163\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3302176\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3531163\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3302176\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10847732736\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=20288569344\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=286821375\n",
      "\t\tMap output records=286821375\n",
      "\t\tMap output bytes=8818110156\n",
      "\t\tMap output materialized bytes=1179844081\n",
      "\t\tInput split bytes=7600\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=285520986\n",
      "\t\tReduce shuffle bytes=1179844081\n",
      "\t\tReduce input records=286821375\n",
      "\t\tReduce output records=3346720\n",
      "\t\tSpilled Records=859862054\n",
      "\t\tShuffled Maps =150\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=150\n",
      "\t\tGC time elapsed (ms)=24507\n",
      "\t\tCPU time spent (ms)=7228680\n",
      "\t\tPhysical memory (bytes) snapshot=65444564992\n",
      "\t\tVirtual memory (bytes) snapshot=238067372032\n",
      "\t\tTotal committed heap usage (bytes)=58103169024\n",
      "\t\tPeak Map Physical memory (bytes)=1147027456\n",
      "\t\tPeak Map Virtual memory (bytes)=4364439552\n",
      "\t\tPeak Reduce Physical memory (bytes)=4604108800\n",
      "\t\tPeak Reduce Virtual memory (bytes)=7036702720\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=13187418894\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=46224720\n",
      "2022-02-06 22:54:57,599 INFO streaming.StreamJob: Output directory: /user/avito/longest-sess/\n",
      "CPU times: user 28 s, sys: 6.95 s, total: 35 s\n",
      "Wall time: 30min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! hdfs dfs -rm -r /user/avito/longest-sess || true\n",
    "! yarn jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "-D mapreduce.job.name=\"max-session-length\" \\\n",
    "-D mapreduce.job.reduces=3 \\\n",
    "-D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \\\n",
    "-D mapreduce.partition.keycomparator.options=\"-k1,1 -k2,2\" \\\n",
    "-D mapreduce.map.output.key.field.separator='+' \\\n",
    "-D mapred.partitioner.class=org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \\\n",
    "-D mapreduce.partition.keypartitioner.options=\"-k1,1\" \\\n",
    "-files ~/storage/utils/longest_sessions.py \\\n",
    "-mapper \"python3 longest_sessions.py map\" \\\n",
    "-reducer \"python3 longest_sessions.py reduce\" \\\n",
    "-input /user/avito/data/ \\\n",
    "-output /user/avito/longest-sess/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "689d0edc",
   "metadata": {
    "id": "689d0edc",
    "outputId": "de1f2d00-e707-42a1-a355-0456957ef7ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2022-02-06 22:54 /user/avito/longest-sess/_SUCCESS\r\n",
      "-rw-r--r--   1 ubuntu hadoop   15403255 2022-02-06 22:53 /user/avito/longest-sess/part-00000\r\n",
      "-rw-r--r--   1 ubuntu hadoop   15405563 2022-02-06 22:53 /user/avito/longest-sess/part-00001\r\n",
      "-rw-r--r--   1 ubuntu hadoop   15415902 2022-02-06 22:54 /user/avito/longest-sess/part-00002\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/avito/longest-sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6187fba2",
   "metadata": {
    "id": "6187fba2",
    "outputId": "7f5f5865-3436-4e18-eb47-d9983bb22d93",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\t319.0\r\n",
      "1000003\t1932.0\r\n",
      "1000009\t978.0\r\n",
      "1000012\t1086.0\r\n",
      "1000015\t0\r\n",
      "1000018\t1488.0\r\n",
      "1000024\t848.0\r\n",
      "1000027\t987.0\r\n",
      "1000030\t4237.0\r\n",
      "1000033\t906.0\r\n",
      "1000036\t995.0\r\n",
      "1000042\t2367.0\r\n",
      "1000045\t2945.0\r\n",
      "1000048\t11772.0\r\n",
      "100005\t585.0\r\n",
      "1000051\t4849.0\r\n",
      "1000054\t2579.0\r\n",
      "1000057\t238.0\r\n",
      "1000066\t1203.0\r\n",
      "1000069\t392.0\r\n",
      "cat: Unable to write to output stream.\r\n",
      "cat: Unable to write to output stream.\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "# Макс. сессия для каждого пользователя, сек.\n",
    "! hdfs dfs -cat /user/avito/longest-sess/part* | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fbba3",
   "metadata": {},
   "source": [
    "2-ой MapReduce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e07dcb6",
   "metadata": {
    "id": "8e07dcb6",
    "outputId": "74d0c8a9-c6a1-410a-d59b-cf763a8a7a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/avito/top10-longest-sess\n",
      "packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-3.2.2.jar] /tmp/streamjob2559297792847900915.jar tmpDir=null\n",
      "2022-02-06 22:58:00,511 INFO client.RMProxy: Connecting to ResourceManager at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:8032\n",
      "2022-02-06 22:58:00,695 INFO client.AHSProxy: Connecting to Application History server at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:10200\n",
      "2022-02-06 22:58:00,722 INFO client.RMProxy: Connecting to ResourceManager at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:8032\n",
      "2022-02-06 22:58:00,723 INFO client.AHSProxy: Connecting to Application History server at rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net/10.128.0.25:10200\n",
      "2022-02-06 22:58:00,914 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1644184388994_0002\n",
      "2022-02-06 22:58:01,212 INFO mapred.FileInputFormat: Total input files to process : 3\n",
      "2022-02-06 22:58:01,701 INFO mapreduce.JobSubmitter: number of splits:21\n",
      "2022-02-06 22:58:02,234 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1644184388994_0002\n",
      "2022-02-06 22:58:02,236 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-02-06 22:58:02,391 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-02-06 22:58:02,391 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-02-06 22:58:02,447 INFO impl.YarnClientImpl: Submitted application application_1644184388994_0002\n",
      "2022-02-06 22:58:02,477 INFO mapreduce.Job: The url to track the job: http://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8088/proxy/application_1644184388994_0002/\n",
      "2022-02-06 22:58:02,478 INFO mapreduce.Job: Running job: job_1644184388994_0002\n",
      "2022-02-06 22:58:08,546 INFO mapreduce.Job: Job job_1644184388994_0002 running in uber mode : false\n",
      "2022-02-06 22:58:08,546 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-02-06 22:58:17,643 INFO mapreduce.Job:  map 5% reduce 0%\n",
      "2022-02-06 22:58:18,649 INFO mapreduce.Job:  map 24% reduce 0%\n",
      "2022-02-06 22:58:19,655 INFO mapreduce.Job:  map 29% reduce 0%\n",
      "2022-02-06 22:58:25,707 INFO mapreduce.Job:  map 33% reduce 0%\n",
      "2022-02-06 22:58:27,720 INFO mapreduce.Job:  map 52% reduce 0%\n",
      "2022-02-06 22:58:28,726 INFO mapreduce.Job:  map 57% reduce 0%\n",
      "2022-02-06 22:58:33,780 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2022-02-06 22:58:34,786 INFO mapreduce.Job:  map 71% reduce 0%\n",
      "2022-02-06 22:58:36,797 INFO mapreduce.Job:  map 76% reduce 0%\n",
      "2022-02-06 22:58:38,808 INFO mapreduce.Job:  map 86% reduce 0%\n",
      "2022-02-06 22:58:39,816 INFO mapreduce.Job:  map 90% reduce 0%\n",
      "2022-02-06 22:58:42,834 INFO mapreduce.Job:  map 95% reduce 0%\n",
      "2022-02-06 22:58:43,840 INFO mapreduce.Job:  map 100% reduce 30%\n",
      "2022-02-06 22:58:49,869 INFO mapreduce.Job:  map 100% reduce 85%\n",
      "2022-02-06 22:58:50,875 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-02-06 22:58:51,886 INFO mapreduce.Job: Job job_1644184388994_0002 completed successfully\n",
      "2022-02-06 22:58:51,961 INFO mapreduce.Job: Counters: 56\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=14095187\n",
      "\t\tFILE: Number of bytes written=34758694\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=47089806\n",
      "\t\tHDFS: Number of bytes written=162\n",
      "\t\tHDFS: Number of read operations=68\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=3\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=21\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=14\n",
      "\t\tRack-local map tasks=7\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=358659\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=132444\n",
      "\t\tTotal time spent by all map tasks (ms)=119553\n",
      "\t\tTotal time spent by all reduce tasks (ms)=22074\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=119553\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=22074\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=367266816\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=135622656\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=3346720\n",
      "\t\tMap output records=3346720\n",
      "\t\tMap output bytes=49571440\n",
      "\t\tMap output materialized bytes=15341377\n",
      "\t\tInput split bytes=3066\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=3346720\n",
      "\t\tReduce shuffle bytes=15341377\n",
      "\t\tReduce input records=3346720\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=6693440\n",
      "\t\tShuffled Maps =21\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=21\n",
      "\t\tGC time elapsed (ms)=3016\n",
      "\t\tCPU time spent (ms)=67450\n",
      "\t\tPhysical memory (bytes) snapshot=9783365632\n",
      "\t\tVirtual memory (bytes) snapshot=98134138880\n",
      "\t\tTotal committed heap usage (bytes)=10101456896\n",
      "\t\tPeak Map Physical memory (bytes)=474206208\n",
      "\t\tPeak Map Virtual memory (bytes)=4341108736\n",
      "\t\tPeak Reduce Physical memory (bytes)=566972416\n",
      "\t\tPeak Reduce Virtual memory (bytes)=7032279040\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=47086740\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=162\n",
      "2022-02-06 22:58:51,961 INFO streaming.StreamJob: Output directory: /user/avito/top10-longest-sess/\n",
      "CPU times: user 887 ms, sys: 218 ms, total: 1.11 s\n",
      "Wall time: 55.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! hdfs dfs -rm -r /user/avito/top10-longest-sess || true\n",
    "! yarn jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "-D mapreduce.job.name=\"top10-session-length\" \\\n",
    "-D mapreduce.job.reduces=1 \\\n",
    "-D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \\\n",
    "-D mapreduce.partition.keycomparator.options=\"-k2,2nr -k1,1\" \\\n",
    "-D mapreduce.map.output.key.field.separator='+' \\\n",
    "-files ~/storage/utils/longest_sessions.py \\\n",
    "-mapper \"python3 longest_sessions.py top_10_map\" \\\n",
    "-reducer \"python3 longest_sessions.py top_10_reduce\" \\\n",
    "-input /user/avito/longest-sess/ \\\n",
    "-output /user/avito/top10-longest-sess/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f23da6b",
   "metadata": {
    "id": "7f23da6b",
    "outputId": "94c39855-8197-4787-c1ca-fd515c3f8837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2022-02-06 22:58 /user/avito/top10-longest-sess/_SUCCESS\r\n",
      "-rw-r--r--   1 ubuntu hadoop        162 2022-02-06 22:58 /user/avito/top10-longest-sess/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/avito/top10-longest-sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f613fcbc",
   "metadata": {
    "id": "f613fcbc",
    "outputId": "2053109b-3c5f-4003-94ae-38cb5e152fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143904\t358181.0\r\n",
      "1113291\t329463.0\r\n",
      "1203081\t170447.0\r\n",
      "4263912\t80605.0\r\n",
      "1987990\t70544.0\r\n",
      "563902\t68359.0\r\n",
      "2853587\t53371.0\r\n",
      "2735474\t49881.0\r\n",
      "1370797\t49791.0\r\n",
      "2271348\t48099.0\r\n"
     ]
    }
   ],
   "source": [
    "# Результат\n",
    "! hdfs dfs -cat /user/avito/top10-longest-sess/part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4532d397",
   "metadata": {
    "id": "4532d397",
    "outputId": "42bbb5a0-c33e-4098-dd2c-f7ad6f159cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-06 23:00:55,016 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2022-02-06 23:00:55,084 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2022-02-06 23:00:55,084 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "2022-02-06 23:00:57,738 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2022-02-06 23:00:57,738 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2022-02-06 23:00:57,738 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cp /user/avito/top10-longest-sess/part-00000 s3a://nsrazuvaevbucket/mhw2-top10-longest-sess.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3420f4",
   "metadata": {
    "id": "3e3420f4"
   },
   "source": [
    "Ссылка на результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-top10-longest-sess.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f878393",
   "metadata": {
    "id": "7f878393"
   },
   "source": [
    "## Задание 2  <a class=\"anchor\" id=\"task-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07abeee",
   "metadata": {},
   "source": [
    "Скачаем и распакуем данные с помощью консоли: \n",
    "\n",
    "```\n",
    "cd\n",
    "kaggle competitions download -c avito-context-ad-clicks -f trainSearchStream.tsv.7z\n",
    "kaggle competitions download -c avito-context-ad-clicks -f SearchInfo.tsv.7z\n",
    "kaggle competitions download -c avito-context-ad-clicks -f AdsInfo.tsv.7z\n",
    "\n",
    "mv trainSearchStream.tsv.7z storage/trainSearchStream.tsv.7z\n",
    "mv SearchInfo.tsv.7z storage/SearchInfo.tsv.7z\n",
    "mv AdsInfo.tsv.7z storage/AdsInfo.tsv.7z\n",
    "cd storage\n",
    "\n",
    "7z x trainSearchStream.tsv.7z -oavito-context-ad-clicks\n",
    "7z x SearchInfo.tsv.7z -oavito-context-ad-clicks\n",
    "7z x AdsInfo.tsv.7z -oavito-context-ad-clicks\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbed65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/storage/avito-context-ad-clicks\n",
      "AdsInfo.tsv\ttrainSearchStream.tsv\t  VisitsStream.tsv\r\n",
      "SearchInfo.tsv\tVisitsStreamNoHeader.tsv\r\n"
     ]
    }
   ],
   "source": [
    "%cd \"~/storage/avito-context-ad-clicks\"\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c514b",
   "metadata": {},
   "source": [
    "Запустим Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab99a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /home/ubuntu/.local/lib/python3.8/site-packages (2.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1a681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decf9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"lsml-app\")\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95777908",
   "metadata": {},
   "source": [
    "Положим данные в hdfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a2e1757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.57 s, sys: 1.84 s, total: 9.41 s\n",
      "Wall time: 7min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! hdfs dfs -put SearchInfo.tsv /user/avito/data/\n",
    "! hdfs dfs -put trainSearchStream.tsv /user/avito/data/\n",
    "! hdfs dfs -put AdsInfo.tsv /user/avito/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e3fc7a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 08:18:04,424 INFO balancer.Balancer: namenodes  = [hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020]\n",
      "2022-02-07 08:18:04,428 INFO balancer.Balancer: parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]\n",
      "2022-02-07 08:18:04,428 INFO balancer.Balancer: included nodes = []\n",
      "2022-02-07 08:18:04,428 INFO balancer.Balancer: excluded nodes = []\n",
      "2022-02-07 08:18:04,429 INFO balancer.Balancer: source nodes = []\n",
      "Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved  NameNode\n",
      "2022-02-07 08:18:04,432 INFO balancer.NameNodeConnector: getBlocks calls for hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020 will be rate-limited to 20 per second\n",
      "2022-02-07 08:18:05,395 INFO balancer.Balancer: dfs.namenode.get-blocks.max-qps = 20 (default=20)\n",
      "2022-02-07 08:18:05,395 INFO balancer.Balancer: dfs.balancer.movedWinWidth = 5400000 (default=5400000)\n",
      "2022-02-07 08:18:05,395 INFO balancer.Balancer: dfs.balancer.moverThreads = 1000 (default=1000)\n",
      "2022-02-07 08:18:05,395 INFO balancer.Balancer: dfs.balancer.dispatcherThreads = 200 (default=200)\n",
      "2022-02-07 08:18:05,396 INFO balancer.Balancer: dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)\n",
      "2022-02-07 08:18:05,396 INFO balancer.Balancer: dfs.balancer.getBlocks.min-block-size = 10485760 (default=10485760)\n",
      "2022-02-07 08:18:05,396 INFO balancer.Balancer: dfs.datanode.balance.max.concurrent.moves = 50 (default=50)\n",
      "2022-02-07 08:18:05,396 INFO balancer.Balancer: dfs.datanode.balance.bandwidthPerSec = 10485760 (default=10485760)\n",
      "2022-02-07 08:18:05,402 INFO balancer.Balancer: dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)\n",
      "2022-02-07 08:18:05,402 INFO balancer.Balancer: dfs.blocksize = 268435456 (default=134217728)\n",
      "2022-02-07 08:18:05,412 INFO net.NetworkTopology: Adding a new node: /default-rack/10.128.0.24:9866\n",
      "2022-02-07 08:18:05,414 INFO balancer.Balancer: 0 over-utilized: []\n",
      "2022-02-07 08:18:05,414 INFO balancer.Balancer: 0 underutilized: []\n",
      "The cluster is balanced. Exiting...\n",
      "Feb 7, 2022 8:18:05 AM            0                  0 B                 0 B                0 B  hdfs://rc1a-dataproc-m-ewr760zc7czy40ae.mdb.yandexcloud.net:8020\n",
      "Feb 7, 2022 8:18:05 AM   Balancing took 1.172 seconds\n"
     ]
    }
   ],
   "source": [
    "! sudo -u hdfs hdfs balancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e65dc0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop  5350670676 2022-02-07 08:17 /user/avito/data/AdsInfo.tsv\r\n",
      "-rw-r--r--   1 ubuntu hadoop  9469373867 2022-02-07 05:10 /user/avito/data/SearchInfo.tsv\r\n",
      "-rw-r--r--   1 ubuntu hadoop 13180996366 2022-02-06 22:21 /user/avito/data/VisitsStreamNoHeader.tsv\r\n",
      "-rw-r--r--   1 ubuntu hadoop 11023566785 2022-02-07 05:16 /user/avito/data/trainSearchStream.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/avito/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b1d3bb",
   "metadata": {},
   "source": [
    "### Пункт 1  <a class=\"anchor\" id=\"task-2-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e258eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SearchID: integer (nullable = true)\n",
      " |-- SearchDate: string (nullable = true)\n",
      " |-- IPID: integer (nullable = true)\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- IsUserLoggedOn: integer (nullable = true)\n",
      " |-- SearchQuery: string (nullable = true)\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- SearchParams: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchInfoDF = se.read.csv(\"/user/avito/data/SearchInfo.tsv\", header=True, inferSchema=True, sep='\\t')\n",
    "searchInfoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b43bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_categories(text):\n",
    "    \"\"\"\n",
    "    Вытаскиваем номер категории рег. выражением\n",
    "    \"\"\"\n",
    "    regexp = r'(\\d+):'\n",
    "    return re.findall(regexp, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f973ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.3 ms, sys: 25.6 ms, total: 80.9 ms\n",
      "Wall time: 4min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('175', 9979618),\n",
       " ('5', 8737931),\n",
       " ('178', 6378281),\n",
       " ('45', 6375642),\n",
       " ('83', 6351296),\n",
       " ('127', 5196744),\n",
       " ('179', 3245870),\n",
       " ('143', 3108130),\n",
       " ('709', 2684001),\n",
       " ('44', 2646546)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Без сохранения в hdfs\n",
    "top10cat = (\n",
    "    searchInfoDF.rdd\n",
    "    # Убираем пропуски\n",
    "    .filter(lambda x: x.SearchParams != None)\n",
    "    # Достаем категории\n",
    "    .flatMap(lambda x: extract_categories(x.SearchParams))\n",
    "    # Считаем\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .takeOrdered(10, lambda x: -x[1])\n",
    ")\n",
    "top10cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2eadf4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 98.3 ms, sys: 58.3 ms, total: 157 ms\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# С автосохранением в hdfs\n",
    "! hdfs dfs -rm -r /user/avito/top10-categories\n",
    "(\n",
    "    searchInfoDF.rdd\n",
    "    # Убираем пропуски\n",
    "    .filter(lambda x: x.SearchParams != None)\n",
    "    # Достаем категории\n",
    "    .flatMap(lambda x: extract_categories(x.SearchParams))\n",
    "    # Считаем\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    # Сортируем для сохранения\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda x: x[1] < 10)\n",
    "    .map(lambda x: x[0])\n",
    "    .saveAsTextFile('/user/avito/top10-categories')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "759e42a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9979618, '175')\r\n",
      "(8737931, '5')\r\n",
      "(6378281, '178')\r\n",
      "(6375642, '45')\r\n",
      "(6351296, '83')\r\n",
      "(5196744, '127')\r\n",
      "(3245870, '179')\r\n",
      "(3108130, '143')\r\n",
      "(2684001, '709')\r\n",
      "(2646546, '44')\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /user/avito/top10-categories/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69f4e234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/avito/top10-categories-merged\r\n"
     ]
    }
   ],
   "source": [
    "# Объединим файлы в 1\n",
    "! hdfs dfs -rm -r /user/avito/top10-categories-merged\n",
    "(\n",
    "    sc.textFile(\"/user/avito/top10-categories/*\")\n",
    "    .map(lambda x: re.findall(r'\\d+', x))\n",
    "    .map(lambda x: '\\t'.join(x[::-1]))\n",
    "    .coalesce(1)\n",
    "    .saveAsTextFile('/user/avito/top10-categories-merged')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49aae7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2022-02-07 06:46 /user/avito/top10-categories-merged/_SUCCESS\r\n",
      "-rw-r--r--   1 ubuntu hadoop        115 2022-02-07 06:46 /user/avito/top10-categories-merged/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/avito/top10-categories-merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a7d6c236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\t9979618\r\n",
      "5\t8737931\r\n",
      "178\t6378281\r\n",
      "45\t6375642\r\n",
      "83\t6351296\r\n",
      "127\t5196744\r\n",
      "179\t3245870\r\n",
      "143\t3108130\r\n",
      "709\t2684001\r\n",
      "44\t2646546\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /user/avito/top10-categories-merged/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8a96b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 06:47:37,724 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2022-02-07 06:47:37,795 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2022-02-07 06:47:37,795 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "2022-02-07 06:47:41,902 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2022-02-07 06:47:41,902 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2022-02-07 06:47:41,902 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cp /user/avito/top10-categories-merged/part-00000 s3a://nsrazuvaevbucket/mhw2-top10-categories.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a56aef",
   "metadata": {},
   "source": [
    "Ссылка на результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-top10-categories.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85927167",
   "metadata": {},
   "source": [
    "### Пункт 2 <a class=\"anchor\" id=\"task-2-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "982d73bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SearchID: integer (nullable = true)\n",
      " |-- AdID: integer (nullable = true)\n",
      " |-- Position: integer (nullable = true)\n",
      " |-- ObjectType: integer (nullable = true)\n",
      " |-- HistCTR: double (nullable = true)\n",
      " |-- IsClick: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSearchStreamDF = se.read.csv(\n",
    "    \"/user/avito/data/trainSearchStream.tsv\", header=True,\n",
    "    inferSchema=True, sep='\\t'\n",
    ")\n",
    "trainSearchStreamDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9bb7a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SearchID: integer (nullable = true)\n",
      " |-- SearchDate: string (nullable = true)\n",
      " |-- IPID: integer (nullable = true)\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- IsUserLoggedOn: integer (nullable = true)\n",
      " |-- SearchQuery: string (nullable = true)\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- SearchParams: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchInfoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb648a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchInfoDF.registerTempTable('searchInfo')\n",
    "trainSearchStreamDF.registerTempTable('trainSearchStream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e371659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Склеим таблицы по SearchID и уберем пропуски\n",
    "searchQueryDF = se.sql(\n",
    "    \"\"\"\n",
    "    SELECT a.SearchID, a.SearchQuery, b.IsClick\n",
    "    FROM \n",
    "        searchInfo a INNER JOIN trainSearchStream b \n",
    "        ON a.SearchID = b.SearchID\n",
    "    WHERE \n",
    "        IsClick = 1 AND SearchQuery IS NOT NULL\n",
    "    \"\"\"\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "355e0c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.1 ms, sys: 16.2 ms, total: 75.3 ms\n",
      "Wall time: 7min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(SearchID=34239, SearchQuery='монопод', IsClick=1),\n",
       " Row(SearchID=90019, SearchQuery='сварочный аппарат бу', IsClick=1),\n",
       " Row(SearchID=96488, SearchQuery='iphone 5s новый', IsClick=1),\n",
       " Row(SearchID=150051, SearchQuery='ваз 2110', IsClick=1),\n",
       " Row(SearchID=154452, SearchQuery='туфли', IsClick=1),\n",
       " Row(SearchID=340002, SearchQuery='счетчик', IsClick=1),\n",
       " Row(SearchID=419385, SearchQuery='микроволновая печь', IsClick=1),\n",
       " Row(SearchID=469345, SearchQuery='мокасины', IsClick=1),\n",
       " Row(SearchID=564376, SearchQuery='продажа велосипеда', IsClick=1),\n",
       " Row(SearchID=567690, SearchQuery='бампер ниссан примера', IsClick=1)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "searchQueryDF.rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "10196c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_words(text):\n",
    "    pattern = re.compile(r\"[a-zа-я]+\")\n",
    "    result = []\n",
    "    for match in pattern.finditer(text.lower()):\n",
    "        word = match.group(0)\n",
    "        result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d446500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/avito/top10-words': No such file or directory\n",
      "CPU times: user 156 ms, sys: 82.6 ms, total: 239 ms\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# С автосохранением в hdfs\n",
    "! hdfs dfs -rm -r /user/avito/top10-words\n",
    "(\n",
    "    searchQueryDF.rdd\n",
    "    # Достаем слова из запросов\n",
    "    .flatMap(lambda x: extract_words(x.SearchQuery))\n",
    "    # Считаем\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    # Сортируем и сохраняем\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda x: x[1] < 10)\n",
    "    .coalesce(1)\n",
    "    .map(lambda x: '\\t'.join(map(str, x[0][::-1])))\n",
    "    .saveAsTextFile('/user/avito/top10-words')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ad6c5b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "велосипед\t12510\r\n",
      "бу\t11211\r\n",
      "iphone\t7439\r\n",
      "для\t5984\r\n",
      "диван\t5734\r\n",
      "s\t5571\r\n",
      "на\t4905\r\n",
      "платье\t4471\r\n",
      "коляска\t3794\r\n",
      "велосипеды\t3780\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /user/avito/top10-words/part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d43e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 08:03:04,368 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2022-02-07 08:03:04,439 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2022-02-07 08:03:04,439 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "2022-02-07 08:03:07,181 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2022-02-07 08:03:07,182 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2022-02-07 08:03:07,182 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cp /user/avito/top10-words/part-00000 s3a://nsrazuvaevbucket/mhw2-top10-words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01170b76",
   "metadata": {},
   "source": [
    "Ссылка на результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-top10-words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66bf8b2",
   "metadata": {},
   "source": [
    "### Пункт 3 <a class=\"anchor\" id=\"task-2-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7e9b58e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AdID: integer (nullable = true)\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- Params: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- IsContext: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adsInfoDF = se.read.csv(\n",
    "    \"/user/avito/data/AdsInfo.tsv\", header=True,\n",
    "    inferSchema=True, sep='\\t'\n",
    ")\n",
    "adsInfoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bea251d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adsInfoDF.registerTempTable('adsInfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0fd38809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_words_with_price(text, price):\n",
    "    pattern = re.compile(r\"[a-zа-я]+\")\n",
    "    result = []\n",
    "    for match in pattern.finditer(text.lower()):\n",
    "        word = match.group(0)\n",
    "        result.append(word)\n",
    "    return zip(result, len(result)*[price])\n",
    "\n",
    "def find_mean(key, group):\n",
    "    group = list(group)\n",
    "    return key, sum(group) / len(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "21cd26eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/avito/top10-mean-price': No such file or directory\n",
      "CPU times: user 110 ms, sys: 54.2 ms, total: 164 ms\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# С автосохранением в hdfs\n",
    "! hdfs dfs -rm -r /user/avito/top10-mean-price\n",
    "(\n",
    "    adsInfoDF.rdd\n",
    "    # Убираем пропуски\n",
    "    .filter(lambda x: (x.Title != None) and (x.Price != None))\n",
    "    # Достаем слова с их стоимостью\n",
    "    .flatMap(lambda x: extract_words_with_price(x.Title, x.Price))\n",
    "    # Групируем по словам, считая среднее\n",
    "    .groupByKey()\n",
    "    .map(lambda x: find_mean(x[0], x[1]))\n",
    "    # Сортируем и сохраняем\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda x: x[1] < 10)\n",
    "    .coalesce(1)\n",
    "    .map(lambda x: '\\t'.join(map(str, x[0][::-1])))\n",
    "    .saveAsTextFile('/user/avito/top10-mean-price')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "726f3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "екуеу\t999999999999.0\r\n",
      "вазя\t999999999999.0\r\n",
      "москвском\t999999999999.0\r\n",
      "аваыаыв\t888888888888.0\r\n",
      "rytrytry\t777777777777.0\r\n",
      "красавы\t500000000249.5\r\n",
      "строимград\t500000000000.0\r\n",
      "универсамы\t450000008000.0\r\n",
      "почивники\t144781144847.66666\r\n",
      "стима\t119870533654.83333\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /user/avito/top10-mean-price/part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f1fea70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 08:59:14,867 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2022-02-07 08:59:14,948 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2022-02-07 08:59:14,948 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "2022-02-07 08:59:17,951 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2022-02-07 08:59:17,951 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2022-02-07 08:59:17,951 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cp /user/avito/top10-mean-price/part-00000 s3a://nsrazuvaevbucket/mhw2-mean-price.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b82002",
   "metadata": {},
   "source": [
    "Ссылка на результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-mean-price.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98a86a",
   "metadata": {},
   "source": [
    "### Пункт 4 <a class=\"anchor\" id=\"task-2-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0716753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+--------------------+\n",
      "|UserID|   IPID|    AdID|            ViewDate|\n",
      "+------+-------+--------+--------------------+\n",
      "| 59703|1259356|  469877|2015-04-25 00:00:...|\n",
      "|154389|1846749|27252551|2015-04-25 00:00:...|\n",
      "|218628|2108380|31685325|2015-04-25 00:00:...|\n",
      "|231535| 837110|18827716|2015-04-25 00:00:...|\n",
      "|282306|1654210|29363673|2015-04-25 00:00:...|\n",
      "|295068| 601505|  588324|2015-04-25 00:00:...|\n",
      "|501897| 158476| 4103261|2015-04-25 00:00:...|\n",
      "|655394| 631692| 9860544|2015-04-25 00:00:...|\n",
      "|765603| 804403|29475627|2015-04-25 00:00:...|\n",
      "|790289| 121085|23309988|2015-04-25 00:00:...|\n",
      "+------+-------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visitsStreamDF = se.read.csv(\n",
    "    \"/user/avito/data/VisitsStreamNoHeader.tsv\", header=False,\n",
    "    inferSchema=True, sep='\\t'\n",
    ")\n",
    "columns = [\n",
    "    'UserID',\n",
    "    'IPID',\n",
    "    'AdID',\n",
    "    'ViewDate'\n",
    "]\n",
    "visitsStreamDF = visitsStreamDF.toDF(*columns)\n",
    "visitsStreamDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254d69b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-04-25 00:00:00 2015-05-20 17:59:51\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "start_date = datetime.datetime.strptime(\n",
    "    visitsStreamDF.head(1)[0].ViewDate, \n",
    "    '%Y-%m-%d %H:%M:%S.%f'\n",
    ")\n",
    "end_date = datetime.datetime.strptime(\n",
    "    visitsStreamDF.tail(1)[0].ViewDate,\n",
    "    '%Y-%m-%d %H:%M:%S.%f'\n",
    ")\n",
    "numdays = (end_date - start_date).days + 1\n",
    "print(start_date, end_date)\n",
    "print(numdays)\n",
    "\n",
    "def check_activity(key, group):\n",
    "    \"\"\"\n",
    "    За время наблюдения прошло 26 дней.\n",
    "    Если пользователь заходил в каждый из них, то\n",
    "    уникальных дней как раз 26.\n",
    "    \"\"\"\n",
    "    if len(set(group)) == 26:\n",
    "        return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0624d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 ms, sys: 80.2 ms, total: 228 ms\n",
      "Wall time: 14min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_days_active_users = (\n",
    "    visitsStreamDF.rdd\n",
    "    .map(lambda x: (x.UserID, x.ViewDate[:10]))\n",
    "    # Группируем по пользователям, возвращая UserID тех,\n",
    "    # кто заходил каждый день\n",
    "    .groupByKey()\n",
    "    .map(lambda x: check_activity(x[0], x[1]))\n",
    "    .collect()\n",
    ")\n",
    "all_days_active_users[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9538f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[682902, 1633302, 344025, 2585682, 985842, 3809718, 851202, 1758438, 590733, 3165526]\n",
      "Всего пользователей, заходивших каждый день: 807\n"
     ]
    }
   ],
   "source": [
    "# Убираем None\n",
    "all_days_active_users = [i for i in all_days_active_users if i != None]\n",
    "print(all_days_active_users[:10])\n",
    "print('Всего пользователей, заходивших каждый день:', len(all_days_active_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16b3a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним результат на всякий случай\n",
    "! mkdir other\n",
    "with open('other/active-users.txt', 'w') as f:\n",
    "    for i in all_days_active_users:\n",
    "        f.write(str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "926f54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 20:26:19,881 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2022-02-07 20:26:19,949 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2022-02-07 20:26:19,949 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "2022-02-07 20:26:23,401 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2022-02-07 20:26:23,402 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2022-02-07 20:26:23,402 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "with open('other/all-days-active-users.txt', 'w') as f:\n",
    "    f.write(str(len(all_days_active_users)))\n",
    "\n",
    "! hdfs dfs -put other/all-days-active-users.txt s3a://nsrazuvaevbucket/mhw2-all-days-active-users.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b7085",
   "metadata": {},
   "source": [
    "Ссылка на результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-all-days-active-users.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a782e73",
   "metadata": {},
   "source": [
    "### Пункт 5 <a class=\"anchor\" id=\"task-2-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90c4421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniq_users_per_day(key, group):\n",
    "    return key, len(set(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c67fae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 225 ms, sys: 102 ms, total: 327 ms\n",
      "Wall time: 25min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    visitsStreamDF.rdd\n",
    "    .map(lambda x: (x.ViewDate[:10], x.UserID))\n",
    "    # Убираем пользователей, заходивших каждый день\n",
    "    .filter(lambda x: x[1] not in all_days_active_users)\n",
    "    # Группируем по дате, считая кол-во уникальных пользователей\n",
    "    .groupByKey()\n",
    "    .map(lambda x: uniq_users_per_day(x[0], x[1]))\n",
    "    # Сортируем и сохраняем\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .sortByKey(ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .map(lambda x: '\\t'.join(map(str, x[0][::-1])))\n",
    "    .coalesce(1)\n",
    "    .saveAsTextFile('/user/avito/uniq-users-per-day')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bab49770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-12\t973248\r\n",
      "2015-05-13\t847446\r\n",
      "2015-05-14\t745904\r\n",
      "2015-05-06\t733027\r\n",
      "2015-05-05\t731624\r\n",
      "2015-05-07\t729708\r\n",
      "2015-05-11\t706240\r\n",
      "2015-04-27\t676433\r\n",
      "2015-05-08\t664982\r\n",
      "2015-04-28\t655791\r\n",
      "2015-04-29\t641148\r\n",
      "2015-05-15\t633132\r\n",
      "2015-05-04\t607205\r\n",
      "2015-04-30\t596224\r\n",
      "2015-05-10\t562151\r\n",
      "2015-04-26\t540051\r\n",
      "2015-05-03\t511687\r\n",
      "2015-04-25\t498069\r\n",
      "2015-05-16\t493577\r\n",
      "2015-05-18\t488250\r\n",
      "2015-05-17\t480968\r\n",
      "2015-05-02\t468010\r\n",
      "2015-05-01\t452800\r\n",
      "2015-05-09\t450135\r\n",
      "2015-05-19\t367777\r\n",
      "2015-05-20\t184972\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /user/avito/uniq-users-per-day/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c660112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-07 21:04:33,361 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2022-02-07 21:04:33,428 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2022-02-07 21:04:33,429 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "2022-02-07 21:04:36,189 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2022-02-07 21:04:36,189 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2022-02-07 21:04:36,190 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cp /user/avito/uniq-users-per-day/part-00000 s3a://nsrazuvaevbucket/mhw2-uniq-users-per-day.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce15ad",
   "metadata": {},
   "source": [
    "Ссылка на результат: https://storage.yandexcloud.net/nsrazuvaevbucket/mhw2-uniq-users-per-day.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27225054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MHW2_Никита_Разуваев.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
